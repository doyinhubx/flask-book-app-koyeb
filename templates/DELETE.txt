192.168.65.3   weather.local


Your docker-compose.yml contains:


ports:
  - "3306:3306"
This tries to expose the Docker MySQL container’s port 3306 to your host machine — but your host’s native MySQL server is already using it.

Hence, Docker can’t bind it again — port conflict.


This makes MySQL available on localhost:3307, so there's no conflict.

Your Flask app inside Docker will still talk to db:3306 just fine — because they are on the same internal network.

You only need the ports: section if you want to access the MySQL DB from outside Docker, e.g., using MySQL Workbench or Sequel Ace.



✅ So why expose 3306 on the host?
Here’s why you might want to expose MySQL (port 3306) to the host machine from Docker:

🔹 1. You want to connect with external tools
If you use:

MySQL Workbench

DBeaver

Sequel Ace

or any other GUI client on your host

...you need to expose the port to reach the MySQL server running inside Docker.


ports:
  - "3306:3306"  # hostPort:containerPort
This makes Docker’s MySQL accessible from the host at localhost:3306.


🔹 2. You want to allow other applications (not in Docker) to connect
If you're running another app outside Docker (e.g., Python on host), and it needs access to the MySQL container, you need that port exposed.

🔒 But if everything you need is in Docker...
If:

You only access MySQL from your Flask app inside Docker

You run migrations/seed inside containers

You don’t need external tools to connect

Then:

❌ You don't need to expose MySQL's port
Just remove the ports: section from docker-compose.yml:


🐳 1. Can MySQL Workbench be installed in Docker?
✅ Yes — technically, you can run Workbench in Docker, but:
It's a GUI application, so running it in Docker requires:

Linux containers with a display server (like X11 or Wayland)

Or routing GUI output to your host using X11 forwarding, VNC, or similar

That’s a bit complicated and clunky, especially on Windows/macOS.

✅ Better approach:
Install MySQL Workbench natively on your host system

Use Docker’s exposed port to connect (e.g., localhost:3306 or localhost:3307)

It’s easier, faster, and fully integrated with your OS clipboard, file browser, etc.

🧠 2. What scenarios require exposing MySQL to the host?
Here are some real-life reasons to expose MySQL from Docker and connect from Python (or any app) running on the host:

🔹 Scenario A: You're developing a data science script or Jupyter notebook
You’re running Python locally (not in Docker)

You want to connect to the database container to query/update data

import pymysql
conn = pymysql.connect(
    host="localhost", port=3306,
    user="root", password="password",
    db="flask_bookdb"
)
🔹 Scenario B: You run Flask locally (outside Docker)
Sometimes developers prefer running the Flask app locally for hot-reloading/debugging

Meanwhile, MySQL is in Docker

You expose MySQL port so Flask (on host) can connect to it

🔹 Scenario C: You’re running automated tests or data imports
A local Python CLI or test suite (outside Docker) seeds or verifies database state

For example: pytest, or a seed.py that connects to Dockerized MySQL

🛡️ If you're fully Dockerized (app + DB):
You don’t need to expose 3306


seed.sql

```
USE flask_bookdb;

INSERT INTO book (title, author, genre, description, isbn, published_date)
VALUES
('Book One', 'Author A', 'Fiction', 'A sample book', '1234567890123', '2021-01-01'),
('Book Two', 'Author B', 'Sci-Fi', 'Another sample book', '9876543210987', '2022-05-05');
```



b. Update workflow:

```
      - name: Log in to Docker Hub
        run: echo "${{ secrets.DOCKER_PASSWORD }}" | docker login -u "${{ secrets.DOCKER_USERNAME }}" --password-stdin

      - name: Build and tag Docker image
        run: docker build -t ${{ secrets.DOCKER_USERNAME }}/flask-book-app:${{ github.sha }} .

      - name: Push to Docker Hub
        run: docker push ${{ secrets.DOCKER_USERNAME }}/flask-book-app:${{ github.sha }}
```






Minikube

✔️ Your Situation
Your context shows only docker-desktop, so you're running kubeadm, the legacy single-node option.




Thanks! Since you're on Windows and running kubectl locally (likely using something like kubeadm, Minikube, or Docker Desktop Kubernetes), the TLS handshake timeout is most likely due to network or firewall issues. Here's how to solve it step-by-step:



# Stage 1: Build the app
FROM node:20-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci

COPY . .
RUN npm run build

# Stage 2: Serve the app
FROM node:20-alpine AS runtime

RUN npm install -g serve
WORKDIR /app
COPY --from=builder /app/public ./public

EXPOSE 8080
CMD ["serve", "-s", "public", "-l", "8080"]

The Dockerfile uses a two-stage approach..Its a better and more efficient approach of building...becuase it save.....compared.

Here is an explanation of what the code does....

Explaine succintly....



By implementing both versions, you'll gain a broader understanding of the YOLO framework, thereby allowing you to compare performance, accuracy, and efficiency across different YOLO architectures.

> **Note:** While Flask mastery will be helpful, don’t worry if you're new to it. This guide is designed to be beginner-friendly, breaking down complex concepts step by step. Whether you're new to object detection and Flask or have some experience, you'll be able to implement YOLO-based object detection in Flask with less complexities!


### Key Features of Flask:

- **Lightweight & Minimalistic:** – Flask comes with only the essentials, such as routing, request handling, and templating, allowing developers to add extensions as needed for databases, authentication, and more.
- **Built-in Development Server & Debugger:** Flask comes with a built-in development server, making it easy to test your application locally during development.
- **Jinja2 Templating**: Flask uses the Jinja2 templating engine, which allows you to create dynamic HTML pages by embedding Python-like expressions and control structures.
- **Extensibility:** Flask’s modular design allows you to add functionality through extensions. For example: Flask-SQLAlchemy for database integration, Flask-WTF for form handling and validation or Flask-Login for user authentication.
- **RESTful Request Handling:** Flask supports RESTful request handling, making it a great choice for building APIs and web services.
- **WSGI Compatibility:** Flask is fully compatible with the Web Server Gateway Interface (WSGI), ensuring it works seamlessly with various web servers and deployment options.

With these capabilities, Flask allows developers to quickly build web applications while keeping full control over the project's structure and dependencies.

> We'll make use of a few of Flask's features as we proceed and see how easy their implementation is.


- **YOLOv3** is a significant iteration in the YOLO series, known for its remarkable object detection capabilities. Developed by **Joseph Redmon and Ali Farhadi**, YOLOv3 improves upon its predecessors (YOLOv1 and YOLOv2) by leveraging a deep neural network with multiple detection scales. This approach utilizes feature maps of varying resolutions, enabling efficient detection of both small and large objects.
- A key enhancement in YOLOv3 is its use of **Darknet-53**, a deeper and more efficient **convolutional neural network (CNN)** backbone compared to YOLOv2’s **Darknet-19**. Darknet-53 incorporates **residual connections** (inspired by ResNet), enhancing feature extraction and improving overall detection accuracy. Additionally, YOLOv3 employs **anchor boxes** - predefined bounding box shapes—to refine object localization.
- Unlike previous versions, which used **softmax** for class prediction, YOLOv3 adopts **independent logistic classifiers**, allowing for **multi-label classification** - enabling an object to belong to multiple classes simultaneously.
- YOLOv3 also strikes an effective balance between accuracy and speed, making it faster than most two-stage object detectors while maintaining competitive precision. Due to its efficiency, it is widely used in real-world applications such as **video surveillance, autonomous driving, and image recognition**.



# ========== YOLOv3 Implementation (Original) ==========
model = cv2.dnn.readNet('models/yolov3.weights', 'models/yolov3.cfg')
layer_names = model.getLayerNames()
unconnected_layers = model.getUnconnectedOutLayers()
output_layers = [layer_names[i[0] - 1] if isinstance(i, np.ndarray) else layer_names[i - 1] 
                  for i in unconnected_layers]

def detect_objects(img):
    height, width = img.shape[:2]
    blob = cv2.dnn.blobFromImage(img, 1/255.0, (416, 416), swapRB=True, crop=False)
    model.setInput(blob)
    outputs = model.forward(output_layers)
    # ... rest of detection logic ...



Multi-Environment 1
Deploy to GKE with Helms
Building a Scalable DevOps Pipeline with Kubernetes, Helm Charts, and GitHub Actions
Building Real-World CI/CD Pipelines for Multi-Environment Hosting with Kubernetes and Helm
Managing Multi-Environment Deployments on a Single Kubernetes Cluster with ArgoCD (Locally)



EXTRAS

Here's how to run your helm install command in PowerShell:

Full PowerShell Command:

```
helm install nginx-ingress ingress-nginx/ingress-nginx `
  --namespace ingress-nginx --create-namespace `
  --set controller.hostNetwork=true `
  --set controller.service.type=NodePort `
  --set controller.service.nodePorts.http=32080 `
  --set controller.service.nodePorts.https=32443
```

Before Running:

Make sure the Helm repo is added:

```
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update
```
Make sure Helm is installed:

You can verify by running:

```
helm version
```
Check Kubernetes connection:

Ensure your cluster is running:

```
kubectl get nodes
```

4. Manually Download the Chart
You can bypass the online download entirely by downloading the Helm chart manually:

Step 1: Download the chart
Go to https://github.com/kubernetes/ingress-nginx/releases
Find version 4.12.3 or latest, and download the .tgz chart file.

Kustomize, Flux, or other GitOps tools

Do I always need to create a helm chart from a kubernetes manifests? I have these maanifests, 

k8s/deployment.yml 

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: weather-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: weather
  template:
    metadata:
      labels:
        app: weather
    spec:
      containers:
        - name: weather-container
          image: weather-app:local
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 8080
```

k8s/service.yml

```
apiVersion: v1
kind: Service
metadata:
  name: weather-service
spec:
  type: NodePort
  selector:
    app: weather
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
      nodePort: 30080
```

What name will show up under the NAME tag if I run this command - kubectl get deployment -o wide. Wha do I need to chnge if I need the name weather to appear. Where do I make the change? in helm chart values.yml or k8s/deployment.yml.

I guess I also need dockefile in all these?

Dockerfile

```
# Stage 1: Build the app using Node
FROM node:20-alpine AS builder

# Set working directory
WORKDIR /app

# Copy and install only production dependencies
COPY package*.json ./
RUN npm ci

# Copy the rest of the files and build
COPY . .
RUN npm run build

# Stage 2: Serve with minimal runtime
FROM node:20-alpine AS runtime

# Install only `serve` globally
RUN npm install -g serve

# Set working directory
WORKDIR /app

# Copy built static files from builder stage
COPY --from=builder /app/public ./public

# Expose port
EXPOSE 8080

# Serve built app
CMD ["serve", "-s", "public", "-l", "8080"]
```



Fresh
------------------------------------------------------
A. Local Build
------------------
docker build -t weather-app:local .
docker run -p 8080:8080 weather-app:local



B. Switch to using NGINX base instead of serve for even leaner static hosting [Later]
----------------------



C. Install NGINX Ingress
----------------------
Normal
------
1. kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.10.1/deploy/static/provider/cloud/deploy.yaml
2. kubectl get pods -n ingress-nginx
3. Create a file called ingress.yaml
4. kubectl apply -f ingress.yaml
5. Modify Your Hosts File (simulate the domain http://weather.local)
6. kubectl get ingress
7. Access: http://weather.local
8. (Optional) Clean Up
   kubectl delete ingress weather-ingress
   kubectl delete -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.10.1/deploy/static/provider/cloud/deploy.yaml

Work around
------
0. choco install kubernetes-helm 
1. Bitnami's NGINX Ingress Controller using helms
2. helm repo add bitnami https://charts.bitnami.com/bitnami
3. helm repo update
4. ```

helm install bitnami-ingress bitnami/nginx-ingress-controller \
  --namespace ingress-nginx --create-namespace \
  --set service.type=NodePort \
  --set service.nodePorts.http=32080 \
  --set service.nodePorts.https=32443
```
5. kubectl get pods -n ingress-nginx
6. kubectl get svc -n ingress-nginx
7. your existing ingress.yaml
8. kubectl apply -f ingress.yaml
9. Map the Hostname Locally - C:\Windows\System32\drivers\etc\hosts
10. Test in Browser - http://weather.local:32080




D. Use TLS/SSL with a self-signed cert? Left out - installed after helms
----------------------




Helms
----------------------
helm uninstall weather





ArgoCD
----------------------

# Create the ArgoCD namespace
kubectl create namespace argocd

# Install ArgoCD using the official manifest
kubectl apply -n argocd -f "https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml"

# (Optional) Expose the ArgoCD server (if using Minikube/Docker Desktop)
kubectl port-forward svc/argocd-server -n argocd 8080:443

Then access ArgoCD at:
🔗 http://localhost:8080









helm install cert-manager jetstack/cert-manager --namespace cert-manager --create-namespace --set installCRDs=true